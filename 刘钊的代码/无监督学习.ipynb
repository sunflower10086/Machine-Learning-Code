{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 无降维\n",
    "### 没有使用sklearn库，自己手写k-means算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import fetch_openml\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "def get_distances(X, k, centroids):\n",
    "    n_samples, n_features = X.shape\n",
    "    \n",
    "    distances = np.zeros([X.shape[0], centroids.shape[0]])\n",
    "    for i, x in enumerate(X):\n",
    "        for j, centroid in enumerate(centroids):\n",
    "            b = sum(np.sqrt((x - centroid)**2))\n",
    "            distances[i][j] = b\n",
    "    \n",
    "    return distances\n",
    "\n",
    "# 定义k-means聚类函数\n",
    "def k_means(X, k, max_iters, callback=None):\n",
    "    n_samples, n_features = X.shape\n",
    "    \n",
    "    # 随机初始化聚类中心, centroids是聚类中心\n",
    "    centroids = X[np.random.choice(n_samples, k, replace=False), :]\n",
    "    \n",
    "    labels = []\n",
    "\n",
    "    # 迭代更新聚类中心\n",
    "    for i in range(max_iters):\n",
    "        # 计算每个样本到聚类中心的距离\n",
    "        distances = get_distances(X, k, centroids)\n",
    "\n",
    "        # 分配每个样本到最近的聚类中心\n",
    "        # labels存储的是每个样本离的最近的聚类中心的索引\n",
    "        # labels的索引相当于每个样本的索引\n",
    "        labels = []\n",
    "        loss = 0 # 误差\n",
    "        for i, distance in enumerate(distances):\n",
    "            d = 0x3f3f3f3f\n",
    "            index = 0\n",
    "            for j, dist in enumerate(distance):\n",
    "                # print(\"dist \", dist)\n",
    "                if dist < d:\n",
    "                    index = j\n",
    "                    d = dist\n",
    "            \n",
    "            # print(d)\n",
    "            loss += d\n",
    "            labels.append(index)\n",
    "\n",
    "        if callback is not None:\n",
    "            # 通过这个回调函数求每次迭代的时候的损失\n",
    "            # 直接加上每个样本到他聚类中心的距离\n",
    "            callback(loss)\n",
    "\n",
    "        # 更新聚类中心\n",
    "        centroids = updataCenterIds(k, labels, centroids)\n",
    "\n",
    "    return labels, centroids\n",
    "\n",
    "def updataCenterIds(k, labels, centroids):\n",
    "\n",
    "    # 这个版本时间复杂度为 O(k*X.shape[0])\n",
    "    for i in range(k):\n",
    "        # 存储到这个聚类中心最近的样本\n",
    "        min_pointer = []\n",
    "        for j, label in enumerate(labels):\n",
    "            if label == i:\n",
    "                min_pointer.append(X[j])\n",
    "        \n",
    "        centroids[i] = np.sum(min_pointer, axis=0) / len(min_pointer)\n",
    "\n",
    "    return centroids\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取训练集数据\n",
    "with open('./MNIST_data/train-images.idx3-ubyte', 'rb') as f:\n",
    "    train_X = np.frombuffer(f.read(), dtype=np.uint8, offset=16).reshape(-1, 28*28)\n",
    "\n",
    "max_iters = 100\n",
    "\n",
    "k = 10\n",
    "\n",
    "X = train_X[:20000]\n",
    "\n",
    "labels, centroids = k_means(X, k, max_iters)\n",
    "print(\"labels\", len(labels))\n",
    "print(\"centroids\", centroids)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn库的k-means算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=10, random_state=42, max_iter= 50)\n",
    "kmeans.fit(X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 降维之后\n",
    "### 先计算降到多少维可以保持80%的方差贡献率"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#求784维的每一维的均值\n",
    "xi = train_X.shape[1]\n",
    "Xmean = np.zeros(xi,dtype=\"f\")#.reshape(xi)\n",
    "Xstd = np.zeros(xi,dtype=\"f\")\n",
    "#规范化的样本数据\n",
    "Strain_X = np.zeros(len(train_X) * xi, dtype=\"f\").reshape(xi, len(train_X))#784*55000\n",
    "\n",
    "print(Strain_X.shape)\n",
    "\n",
    "for i in range(xi):#784\n",
    "    Xmean[i] = np.mean(train_X[:,i]) #求第i维向量的所有数据点的均值\n",
    "    Xstd[i] = np.std(train_X[:,i], ddof=1) #求第i维向量的所有数据点的标准差\n",
    "\n",
    "print(len(train_X))\n",
    "\n",
    "# #规范化所有样本数据\n",
    "for i in range(len(train_X)):\n",
    "    for j in range(xi):\n",
    "        # print(train_X[i][j].T-Xmean[j])\n",
    "        Strain_X[j][i] = (train_X[i][j].T-Xmean[j])#不归一化\n",
    "Strain_X"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 样本相关矩阵(均值为零，方差不为1) 784*784(协方差矩阵)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = (1 / len(train_X) - 1) * (np.dot(Strain_X, Strain_X.T))\n",
    "R"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 奇异值分解求特征值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "# 奇异值分解\n",
    "U,S,VT =np.linalg.svd(R) #VT 的 i 行对应 i 个特征值的特征向量\n",
    "\n",
    "# 奇异值开根求特征值\n",
    "S1=np.zeros(len(S)).reshape(len(S),1)\n",
    "for i in range(len(S)):\n",
    "    S1[i] = math.sqrt(S[i])\n",
    "sorted(S1, reverse=True)\n",
    "S1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 求累计方差贡献率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miuk = 0.8\n",
    "addS = 0\n",
    "#记录累加方程贡献率在大于miuk时，有多少个主成分\n",
    "cnt = 0\n",
    "\n",
    "for i in range(len(S)):\n",
    "    addS += S1[i]\n",
    "    cnt += 1\n",
    "    if((addS / sum(S1)) >= miuk):\n",
    "        cnt = i\n",
    "        break\n",
    "print(cnt)\n",
    "\n",
    "# 进行降维\n",
    "pca =PCA(n_components =cnt + 1)\n",
    "pca.fit(train_X)\n",
    "X=pca.transform(train_X)# 降维后的结果"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 通过自己手写的k-means算法进行聚类，并且与没有降维之前作比较"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 原本的60000个样本点太多了，跑不出来，少选几个\n",
    "X = X[:20000]\n",
    "\n",
    "labels, centroids = k_means(X, k, max_iters)\n",
    "print(\"labels\", len(labels))\n",
    "print(\"centroids\", centroids)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用k-means对降维之后的数据进行聚类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=10, random_state=42, max_iter= 50)\n",
    "kmeans.fit(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
